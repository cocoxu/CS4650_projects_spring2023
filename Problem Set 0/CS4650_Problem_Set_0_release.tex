\documentclass[11pt, letterpaper]{article}
\usepackage[utf8]{inputenc}

\makeatletter
\newcommand{\@BIBLABEL}{\@emptybiblabel}
\newcommand{\@emptybiblabel}[1]{}
\newcommand*{\permcomb}[4][0mu]{{{}^{#3}\mkern#1#2_{#4}}}
\newcommand{\perm}[1][-3mu]{\permcomb[#1]{P}}
\makeatother
\usepackage[hidelinks]{hyperref}
\usepackage{comment}
\usepackage{enumitem}
\usepackage{fullpage}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{tabularx}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage[margin=0.7in]{geometry}    % For reducing margin
\usepackage[english]{babel}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage{physics}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{fullpage}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{comment}
\usepackage{framed}

\begin{document}

\title{CS 4650: Natural Language Processing (Spring 2023) \\ Problem Set 0}
\author{Instructor: Wei Xu \\ TAs: Rahul Katre, Marcus Ma, Mounica Maddela, Ben Podrazhansky
\\Piazza: \url{https://piazza.com/gatech/spring2023/cs4650}
\\Gradescope: \url{https://www.gradescope.com/courses/481426}}
\date{Due: Thursday, Januray 12, 11:59 PM ET}
\maketitle

{\Large \textbf{Instruction}}
\begin{enumerate}
    \item This Problem Set 0 (together with Programming Project 0) is meant to serve as a background preparation test, and to help students decide whether they have enough math/programming skills to succeed in this class. As PS0 is a background test, collaboration and discussion are \textbf{NOT} allowed. All of the questions represent materials that students are expected to be familiar with before they take this class and/or by the end of the first week. PS0 is part of the coursework for the first week and will be counted towards 4\%  of the final grade. 
    
    \item As one of the most advanced AI classes, CS 4650 covers deep learning and other machine learning models in the context of processing text data. The lectures will contain a lot of math (i.e., linear algebra, probability, and multivariate calculus) and the actual programming assignments will be of a larger scale and much more challenging to debug than Project 0. You are strongly recommended/required to take CS 4641/7641 (Machine Learning) and (Math 2550 or Math 2551 or Math 2561 or Math 2401 or Math 24X1 or 2X51) \textbf{before} taking this class (not in the same semester while taking this class). Taking CS 4644/7643 (Deep Learning) first will also help you understand the class material better, and complete and debug the programming homework in this course with more ease.

    
    \item Write out all steps required to find the solutions so that partial credit may be awarded.
    
    \item You may find the lecture note on matrix calculus by Randal J. Barnes helpful: \url{https://atmos.washington.edu/~dennis/MatrixCalculus.pdf}. 
    
    \item Submit your answers as a pdf file on Gradescope. When submitting to Gradescope, make sure to mark page(s) correspond to each problem or subproblem. We recommend students type answers with LaTeX or word processors. A scanned handwritten copy would also be acceptable (but hard copies will not be accepted). If writing by hand, write as clearly as possible. No credit may be given to unreadable handwriting. If you cannot access Gradescope the day when Problem Set 0 (PS0) is due, please email your submission to the instructor with ``CS 4650 - PS0'' in the title. 
    
    \item \textbf{For students on the wait list}: we don't have any additional information on whether you will be able to enroll in the course (it will largely depend on when/whether students currently enrolled will drop the class before registration closes). If you are on the waitlist and plan to take the class, please complete and submit Problem Set 0 by the due time. If you get off the waitlist, you will be automatically added to Gradescope after about a day. If you still cannot access Gradescope by the due date, please send a private message to the teaching team on Piazza (we will manually add you to Gradescope) and email your submission to the instructor as mentioned above in (5).
\end{enumerate}

\newpage
\section{Linear Algebra}
\begin{enumerate}[label=(\alph*)]

	\item (\textbf{3 pts}) Compute the $l_1$ norm, $l_2$ norm, and $l_\infty$ norm of the vector $\mathbf{x}=\begin{bmatrix} -5 \\ -1 \\ 6 \end{bmatrix}$.
	
	\item (\textbf{1 pts}) Compute vector $\mathbf{x}$ as the solution to the following linear equation:
	       $
	       \begin{bmatrix} 
                1 & 5 \\
                -2 & 3 
           \end{bmatrix}
           \mathbf{x} =
           \begin{bmatrix} 
                7  \\
                -1
           \end{bmatrix}
           $
           
	\item (\textbf{3 pts}) Provide answers to the following operations ($^\top$ transposes a vector or matrix):
	\begin{enumerate}[label=(\roman*)]
	
        \item Dot product -- $\mathbf{w} = \begin{bmatrix}
2\\
0\\
6\\
\end{bmatrix}$, $\mathbf{x}= \begin{bmatrix}
-5\\
-1\\
3\\
\end{bmatrix}$, then $\mathbf{w}^\top\mathbf{x} = $?
        \item Matrix product --
	       $\mathbf{A} = \begin{bmatrix} 
                1 &  -1 & -4\\
                2 & 6 & 0\\
           \end{bmatrix}$, 
           $\mathbf{B} = \begin{bmatrix} 
                -3 & 7\\
                5 & 2\\
                3 & -4\\
            \end{bmatrix}$, then $\mathbf{A}\mathbf{B}$ = ?
           

        \item Elementwise product -- same $\mathbf{A}$ and $\mathbf{B}$ as above, what is $\mathbf{A}\odot\mathbf{B^\top}$ = ?
    \end{enumerate}
\end{enumerate}

\newpage
\section{Geometry}
\begin{enumerate}[label=(\alph*)]
    \item (\textbf{2 pts}) True or False (if false, explain why)?  $||\alpha\mathbf{u} + \mathbf{v}||^2 = \alpha^2||\mathbf{u}||^2 + ||\mathbf{v}||^2$, where $||\cdot||$ denotes Euclidean norm, $\alpha$ is a scalar, $\mathbf{u}$ and $\mathbf{v}$ are vectors.
    \item (\textbf{2 pts}) Show that the vector $\mathbf{w}$ is orthogonal to the line $\mathbf{w}^\top\mathbf{x} + b = 0$. (\textit{Hint}: consider two points $\mathbf{x}_1$ and $\mathbf{x}_2$ that lie on the line.)
\end{enumerate}

\newpage
\section{Multivariate Calculus}
\begin{enumerate}[label=(\alph*)]
	\item (\textbf{2 pts}) The number of members of a gym in  Midtown Atlanta grows approximately as a function of the number of weeks, $t$, in the first year it is opened: $f(t) = 100 (60 + 5t)^{2/3}$. How fast was the membership increasing initially (i.e., what is the gradient of $f(t)$ when $t=0$)?
	
    \item (\textbf{2 pts}) Consider the equations $L = (1 - z)^2$, $z = w_2y + b$, and $y = w_1x$.\\Compute the gradients $\frac{\partial L}{\partial w_1}$, $\frac{\partial L}{\partial w_2}$, and $\frac{\partial L}{\partial b}$.


	\item Let $\mathbf{c}$ be a column vector. Let $\mathbf{x}$ be another column vector of the same dimension. 


    \begin{enumerate}[label=(\roman*)]
       %\item (\textbf{1 pts}) Write out the expression of the vector product $\mathbf{c}^\top\mathbf{x}$.
	   \item (\textbf{1 pts}) Consider a linear function $f(\mathbf{x})=\mathbf{c}^\top\mathbf{x}$. Compute the gradient $\frac{\partial}{\partial\mathbf{x}}f(\mathbf{x})$.
	   \item (\textbf{1 pts}) Consider a quadratic function $g(\mathbf{x})=\frac{1}{2}\mathbf{x}^\top\mathbf{H}\mathbf{x}$ where $\mathbf{H}$ is a square matrix of dimensions compatible with $\mathbf{x}$. Compute the gradient $\frac{\partial}{\partial\mathbf{x}}g(\mathbf{x})$.
	   \item (\textbf{2 pts}) Let
	   $h(\mathbf{x})=\frac{1}{2}\mathbf{x}^T\mathbf{H}\mathbf{x}+\mathbf{c}^T\mathbf{x}$, where $\mathbf{H} = \begin{bmatrix} 
                2 & 0\\
                0 & 4\\
           \end{bmatrix}$ and $\mathbf{c} = \begin{bmatrix} 1 \\ 4\end{bmatrix}$. When the gradient $\frac{\partial}{\partial\mathbf{x}}h(\mathbf{x}) = 0$, what is $\mathbf{x} =$? Is it a local minimum, maximum or saddle point? 
    \end{enumerate}
    
\end{enumerate}

\newpage
\section{Probability}
\begin{enumerate}[label=(\alph*)]

\item (\textbf{2 pts}) Georgia Tech's Robotics Lab has designed a robot that either takes one step forward or backward. The probability that it takes a forward step is 0.3. Find the probability that at end of 8 steps it is 2 steps away from the starting point?


\item (\textbf{2 pts}) Let $A$ be the event that a patient has a fever, and let $B$ be the event that a patient has contracted the flu. Assume $P(A) = 0.3$ and $P(B) = 0.1$. The probability that a patient has a fever, given that they have the flu is $P(A\mid B) = 0.9$. A new patient has arrived in the hospital, and they have a fever. What is the probability of them having the flu?

    \item
        A probability density function is defined by
        $$
	        f(x)=
	        \begin{cases}
		        Ce^{-x} & \text{if } x>0, \\
		        0 & \text{otherwise}.
	        \end{cases}
        $$
        \begin{enumerate}[label=(\roman*)]
	        \item (\textbf{1 pts}) Find the value of $C$ that makes $f(x)$ a valid probability density function.
	        \item (\textbf{1 pts}) Compute the expected value of $x$, i.e., $E(x)$.
        \end{enumerate}



\end{enumerate}

\end{document}
